{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Wd5oGr_PP4an"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from time import time \n",
    "import multiprocessing\n",
    "import logging  # logger\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Category</th>\n",
       "      <th>Documents</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Noun Phrases</th>\n",
       "      <th>Noun Count</th>\n",
       "      <th>Adjective Count</th>\n",
       "      <th>Verb Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>wall st bear claw back black reuters reuters s...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>carlyle look toward commercial aerospace reute...</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>oil economy cloud stock outlook reuters reuter...</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>iraq halt oil export main southern pipeline re...</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>oil price soar time record posing new menace e...</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  News Category                                          Documents  \\\n",
       "0      business  wall st bear claw back black reuters reuters s...   \n",
       "1      business  carlyle look toward commercial aerospace reute...   \n",
       "2      business  oil economy cloud stock outlook reuters reuter...   \n",
       "3      business  iraq halt oil export main southern pipeline re...   \n",
       "4      business  oil price soar time record posing new menace e...   \n",
       "\n",
       "   Word Count  Noun Phrases  Noun Count  Adjective Count  Verb Count  \n",
       "0          18             4          12                3           2  \n",
       "1          27             5          15                4           3  \n",
       "2          24             5          17                4           2  \n",
       "3          28             3          19                6           3  \n",
       "4          28             4          16                7           3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_path = os.path.abspath(os.path.join(os.pardir,'data','cleaned_AG.csv'))\n",
    "data = pd.read_csv(data_file_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Title & Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Category</th>\n",
       "      <th>Documents</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Noun Phrases</th>\n",
       "      <th>Noun Count</th>\n",
       "      <th>Adjective Count</th>\n",
       "      <th>Verb Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>[wall, st, bear, claw, back, black, reuters, r...</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>[carlyle, look, toward, commercial, aerospace,...</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>[oil, economy, cloud, stock, outlook, reuters,...</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>[iraq, halt, oil, export, main, southern, pipe...</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>[oil, price, soar, time, record, posing, new, ...</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  News Category                                          Documents  \\\n",
       "0      business  [wall, st, bear, claw, back, black, reuters, r...   \n",
       "1      business  [carlyle, look, toward, commercial, aerospace,...   \n",
       "2      business  [oil, economy, cloud, stock, outlook, reuters,...   \n",
       "3      business  [iraq, halt, oil, export, main, southern, pipe...   \n",
       "4      business  [oil, price, soar, time, record, posing, new, ...   \n",
       "\n",
       "   Word Count  Noun Phrases  Noun Count  Adjective Count  Verb Count  \n",
       "0          18             4          12                3           2  \n",
       "1          27             5          15                4           3  \n",
       "2          24             5          17                4           2  \n",
       "3          28             3          19                6           3  \n",
       "4          28             4          16                7           3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Documents'] = data['Documents'].str.split(\" \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings using Word2Vec algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:20:41: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=100, alpha=0.03)', 'datetime': '2021-05-09T00:20:41.325171', 'gensim': '4.0.1', 'python': '3.7.5 (default, Oct 25 2019, 10:52:18) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "# initializing word2vec model\n",
    "model = Word2Vec(min_count=20,\n",
    "                     window=2, # window size for context \n",
    "                     vector_size=100,  # no of features \n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:20:41: collecting all words and their counts\n",
      "INFO - 00:20:41: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:20:41: PROGRESS: at sentence #10000, processed 273130 words, keeping 18981 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #20000, processed 542961 words, keeping 26350 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #30000, processed 810845 words, keeping 31364 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #40000, processed 1079542 words, keeping 35363 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #50000, processed 1347719 words, keeping 38795 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #60000, processed 1617217 words, keeping 42012 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #70000, processed 1887970 words, keeping 44832 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #80000, processed 2156362 words, keeping 47460 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #90000, processed 2420763 words, keeping 50103 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #100000, processed 2685958 words, keeping 52494 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #110000, processed 2951158 words, keeping 54723 word types\n",
      "INFO - 00:20:42: PROGRESS: at sentence #120000, processed 3217943 words, keeping 56786 word types\n",
      "INFO - 00:20:42: collected 58107 word types from a corpus of 3420491 raw words and 127600 sentences\n",
      "INFO - 00:20:42: Creating a fresh vocabulary\n",
      "INFO - 00:20:42: Word2Vec lifecycle event {'msg': 'effective_min_count=20 retains 12033 unique words (20.70834839176003%% of original 58107, drops 46074)', 'datetime': '2021-05-09T00:20:42.812846', 'gensim': '4.0.1', 'python': '3.7.5 (default, Oct 25 2019, 10:52:18) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 00:20:42: Word2Vec lifecycle event {'msg': 'effective_min_count=20 leaves 3242708 word corpus (94.80241286996517%% of original 3420491, drops 177783)', 'datetime': '2021-05-09T00:20:42.813652', 'gensim': '4.0.1', 'python': '3.7.5 (default, Oct 25 2019, 10:52:18) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 00:20:42: deleting the raw counts dictionary of 58107 items\n",
      "INFO - 00:20:42: sample=6e-05 downsamples 1226 most-common words\n",
      "INFO - 00:20:42: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1974354.8758255735 word corpus (60.9%% of prior 3242708)', 'datetime': '2021-05-09T00:20:42.895067', 'gensim': '4.0.1', 'python': '3.7.5 (default, Oct 25 2019, 10:52:18) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO - 00:20:43: estimated required memory for 12033 words and 100 dimensions: 15642900 bytes\n",
      "INFO - 00:20:43: resetting layer weights\n",
      "INFO - 00:20:43: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-05-09T00:20:43.029920', 'gensim': '4.0.1', 'python': '3.7.5 (default, Oct 25 2019, 10:52:18) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "# build vocabulary\n",
    "model.build_vocab(data['Documents'], progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:20:43: Word2Vec lifecycle event {'msg': 'training model with 7 workers on 12033 vocabulary and 100 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2', 'datetime': '2021-05-09T00:20:43.037260', 'gensim': '4.0.1', 'python': '3.7.5 (default, Oct 25 2019, 10:52:18) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO - 00:20:44: EPOCH 1 - PROGRESS: at 40.37% examples, 799298 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:20:45: EPOCH 1 - PROGRESS: at 78.09% examples, 768041 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:20:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:20:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:20:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:20:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:20:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:45: EPOCH - 1 : training on 3420491 raw words (1973893 effective words) took 2.6s, 768329 effective words/s\n",
      "INFO - 00:20:46: EPOCH 2 - PROGRESS: at 40.08% examples, 788249 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:20:47: EPOCH 2 - PROGRESS: at 73.35% examples, 719516 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:20:48: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:20:48: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:20:48: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:20:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:20:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:48: EPOCH - 2 : training on 3420491 raw words (1974381 effective words) took 2.8s, 696735 effective words/s\n",
      "INFO - 00:20:49: EPOCH 3 - PROGRESS: at 34.25% examples, 668666 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:20:50: EPOCH 3 - PROGRESS: at 68.04% examples, 664127 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:20:51: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:20:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:20:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:20:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:20:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:51: EPOCH - 3 : training on 3420491 raw words (1973670 effective words) took 2.9s, 676372 effective words/s\n",
      "INFO - 00:20:52: EPOCH 4 - PROGRESS: at 33.37% examples, 655053 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:20:53: EPOCH 4 - PROGRESS: at 68.34% examples, 670693 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:20:54: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:20:54: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:20:54: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:20:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:20:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:54: EPOCH - 4 : training on 3420491 raw words (1974672 effective words) took 2.9s, 680511 effective words/s\n",
      "INFO - 00:20:55: EPOCH 5 - PROGRESS: at 31.32% examples, 621081 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 00:20:56: EPOCH 5 - PROGRESS: at 65.68% examples, 646713 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:20:57: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:20:57: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:20:57: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:20:57: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:20:57: EPOCH 5 - PROGRESS: at 99.40% examples, 650907 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 00:20:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:20:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:20:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:20:57: EPOCH - 5 : training on 3420491 raw words (1973368 effective words) took 3.0s, 651398 effective words/s\n",
      "INFO - 00:20:58: EPOCH 6 - PROGRESS: at 28.40% examples, 563655 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:20:59: EPOCH 6 - PROGRESS: at 57.44% examples, 564799 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:00: EPOCH 6 - PROGRESS: at 88.09% examples, 572094 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:00: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:00: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:00: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:00: EPOCH - 6 : training on 3420491 raw words (1974480 effective words) took 3.4s, 574865 effective words/s\n",
      "INFO - 00:21:01: EPOCH 7 - PROGRESS: at 28.39% examples, 553212 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 00:21:02: EPOCH 7 - PROGRESS: at 58.60% examples, 570404 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:03: EPOCH 7 - PROGRESS: at 86.06% examples, 555193 words/s, in_qsize 14, out_qsize 1\n",
      "INFO - 00:21:04: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:04: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:04: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:04: EPOCH - 7 : training on 3420491 raw words (1974663 effective words) took 3.5s, 567333 effective words/s\n",
      "INFO - 00:21:05: EPOCH 8 - PROGRESS: at 25.49% examples, 501629 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:06: EPOCH 8 - PROGRESS: at 52.80% examples, 518002 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 00:21:07: EPOCH 8 - PROGRESS: at 81.66% examples, 531963 words/s, in_qsize 14, out_qsize 1\n",
      "INFO - 00:21:07: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:07: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:07: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:07: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:07: EPOCH - 8 : training on 3420491 raw words (1973570 effective words) took 3.6s, 541862 effective words/s\n",
      "INFO - 00:21:08: EPOCH 9 - PROGRESS: at 26.95% examples, 537311 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:09: EPOCH 9 - PROGRESS: at 56.86% examples, 562312 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:10: EPOCH 9 - PROGRESS: at 87.22% examples, 571399 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:11: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:11: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:11: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:11: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:11: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:21:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:11: EPOCH - 9 : training on 3420491 raw words (1974526 effective words) took 3.5s, 570533 effective words/s\n",
      "INFO - 00:21:12: EPOCH 10 - PROGRESS: at 28.97% examples, 575823 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:13: EPOCH 10 - PROGRESS: at 55.71% examples, 550810 words/s, in_qsize 11, out_qsize 2\n",
      "INFO - 00:21:14: EPOCH 10 - PROGRESS: at 86.34% examples, 565840 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:14: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:14: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:14: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:14: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:14: EPOCH - 10 : training on 3420491 raw words (1974224 effective words) took 3.5s, 562011 effective words/s\n",
      "INFO - 00:21:15: EPOCH 11 - PROGRESS: at 26.08% examples, 517392 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:17: EPOCH 11 - PROGRESS: at 55.71% examples, 541971 words/s, in_qsize 14, out_qsize 2\n",
      "INFO - 00:21:18: EPOCH 11 - PROGRESS: at 82.83% examples, 535498 words/s, in_qsize 13, out_qsize 1\n",
      "INFO - 00:21:18: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:18: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:18: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:18: EPOCH - 11 : training on 3420491 raw words (1974346 effective words) took 3.6s, 550153 effective words/s\n",
      "INFO - 00:21:19: EPOCH 12 - PROGRESS: at 29.55% examples, 581296 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:20: EPOCH 12 - PROGRESS: at 60.05% examples, 592098 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:21: EPOCH 12 - PROGRESS: at 89.57% examples, 586869 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:21: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:21: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:21: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:21: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:21: EPOCH - 12 : training on 3420491 raw words (1975065 effective words) took 3.4s, 589560 effective words/s\n",
      "INFO - 00:21:22: EPOCH 13 - PROGRESS: at 27.24% examples, 539218 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:23: EPOCH 13 - PROGRESS: at 55.41% examples, 541552 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:24: EPOCH 13 - PROGRESS: at 86.63% examples, 563457 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 00:21:25: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:25: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:25: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:25: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:25: EPOCH - 13 : training on 3420491 raw words (1974606 effective words) took 3.5s, 569458 effective words/s\n",
      "INFO - 00:21:26: EPOCH 14 - PROGRESS: at 26.66% examples, 527268 words/s, in_qsize 10, out_qsize 3\n",
      "INFO - 00:21:27: EPOCH 14 - PROGRESS: at 51.37% examples, 507739 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:28: EPOCH 14 - PROGRESS: at 78.68% examples, 514368 words/s, in_qsize 11, out_qsize 2\n",
      "INFO - 00:21:29: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:29: EPOCH - 14 : training on 3420491 raw words (1974603 effective words) took 3.8s, 518552 effective words/s\n",
      "INFO - 00:21:30: EPOCH 15 - PROGRESS: at 24.05% examples, 475459 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:31: EPOCH 15 - PROGRESS: at 49.07% examples, 480753 words/s, in_qsize 14, out_qsize 1\n",
      "INFO - 00:21:32: EPOCH 15 - PROGRESS: at 76.31% examples, 497801 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:33: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:33: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:33: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:33: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:33: EPOCH - 15 : training on 3420491 raw words (1974450 effective words) took 4.0s, 498555 effective words/s\n",
      "INFO - 00:21:34: EPOCH 16 - PROGRESS: at 25.49% examples, 494607 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:35: EPOCH 16 - PROGRESS: at 50.50% examples, 492403 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:36: EPOCH 16 - PROGRESS: at 77.19% examples, 500885 words/s, in_qsize 12, out_qsize 3\n",
      "INFO - 00:21:37: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:37: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:37: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:37: EPOCH - 16 : training on 3420491 raw words (1975512 effective words) took 3.9s, 508965 effective words/s\n",
      "INFO - 00:21:38: EPOCH 17 - PROGRESS: at 23.45% examples, 454450 words/s, in_qsize 14, out_qsize 1\n",
      "INFO - 00:21:39: EPOCH 17 - PROGRESS: at 48.77% examples, 464702 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:40: EPOCH 17 - PROGRESS: at 74.84% examples, 475563 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:41: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:41: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:41: EPOCH 17 - PROGRESS: at 98.81% examples, 474088 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 00:21:41: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:41: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:41: EPOCH - 17 : training on 3420491 raw words (1974859 effective words) took 4.1s, 476644 effective words/s\n",
      "INFO - 00:21:42: EPOCH 18 - PROGRESS: at 24.62% examples, 490339 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:43: EPOCH 18 - PROGRESS: at 48.19% examples, 475283 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:44: EPOCH 18 - PROGRESS: at 71.88% examples, 467565 words/s, in_qsize 13, out_qsize 1\n",
      "INFO - 00:21:45: EPOCH 18 - PROGRESS: at 96.59% examples, 468821 words/s, in_qsize 12, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:21:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:45: EPOCH - 18 : training on 3420491 raw words (1974944 effective words) took 4.2s, 472398 effective words/s\n",
      "INFO - 00:21:46: EPOCH 19 - PROGRESS: at 21.40% examples, 425696 words/s, in_qsize 14, out_qsize 3\n",
      "INFO - 00:21:47: EPOCH 19 - PROGRESS: at 45.87% examples, 450257 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:48: EPOCH 19 - PROGRESS: at 72.17% examples, 469710 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:49: EPOCH 19 - PROGRESS: at 96.29% examples, 470078 words/s, in_qsize 11, out_qsize 2\n",
      "INFO - 00:21:49: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:49: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:49: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:49: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:49: EPOCH - 19 : training on 3420491 raw words (1973886 effective words) took 4.1s, 475830 effective words/s\n",
      "INFO - 00:21:50: EPOCH 20 - PROGRESS: at 23.75% examples, 459304 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:51: EPOCH 20 - PROGRESS: at 47.62% examples, 461277 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:52: EPOCH 20 - PROGRESS: at 72.76% examples, 471176 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:53: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:53: EPOCH 20 - PROGRESS: at 99.11% examples, 480882 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 00:21:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:53: EPOCH - 20 : training on 3420491 raw words (1973992 effective words) took 4.1s, 482767 effective words/s\n",
      "INFO - 00:21:54: EPOCH 21 - PROGRESS: at 21.99% examples, 435459 words/s, in_qsize 14, out_qsize 1\n",
      "INFO - 00:21:55: EPOCH 21 - PROGRESS: at 48.19% examples, 475346 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:21:56: EPOCH 21 - PROGRESS: at 69.81% examples, 453293 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:21:57: EPOCH 21 - PROGRESS: at 95.12% examples, 459760 words/s, in_qsize 14, out_qsize 2\n",
      "INFO - 00:21:57: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:21:57: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:21:57: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:21:57: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:21:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:21:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:21:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:21:58: EPOCH - 21 : training on 3420491 raw words (1974329 effective words) took 4.2s, 466352 effective words/s\n",
      "INFO - 00:21:59: EPOCH 22 - PROGRESS: at 26.37% examples, 514948 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:00: EPOCH 22 - PROGRESS: at 50.22% examples, 493652 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:01: EPOCH 22 - PROGRESS: at 73.35% examples, 477669 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:02: EPOCH 22 - PROGRESS: at 98.05% examples, 478495 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 00:22:02: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:02: EPOCH - 22 : training on 3420491 raw words (1973693 effective words) took 4.1s, 477626 effective words/s\n",
      "INFO - 00:22:03: EPOCH 23 - PROGRESS: at 21.70% examples, 430264 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:04: EPOCH 23 - PROGRESS: at 45.88% examples, 452578 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:05: EPOCH 23 - PROGRESS: at 69.22% examples, 452588 words/s, in_qsize 14, out_qsize 1\n",
      "INFO - 00:22:06: EPOCH 23 - PROGRESS: at 91.93% examples, 449549 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:06: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:06: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:06: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:06: EPOCH - 23 : training on 3420491 raw words (1974128 effective words) took 4.3s, 455368 effective words/s\n",
      "INFO - 00:22:07: EPOCH 24 - PROGRESS: at 21.70% examples, 394162 words/s, in_qsize 14, out_qsize 5\n",
      "INFO - 00:22:08: EPOCH 24 - PROGRESS: at 45.30% examples, 426704 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:09: EPOCH 24 - PROGRESS: at 68.04% examples, 432440 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:10: EPOCH 24 - PROGRESS: at 96.58% examples, 460805 words/s, in_qsize 12, out_qsize 0\n",
      "INFO - 00:22:10: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:10: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:10: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:10: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:10: EPOCH - 24 : training on 3420491 raw words (1975023 effective words) took 4.3s, 463654 effective words/s\n",
      "INFO - 00:22:11: EPOCH 25 - PROGRESS: at 22.86% examples, 441910 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:12: EPOCH 25 - PROGRESS: at 48.78% examples, 475595 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:13: EPOCH 25 - PROGRESS: at 73.36% examples, 476023 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:14: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:14: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:14: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:14: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:14: EPOCH - 25 : training on 3420491 raw words (1974545 effective words) took 4.0s, 493852 effective words/s\n",
      "INFO - 00:22:15: EPOCH 26 - PROGRESS: at 26.07% examples, 504463 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:16: EPOCH 26 - PROGRESS: at 53.38% examples, 521834 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:17: EPOCH 26 - PROGRESS: at 80.49% examples, 520789 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:18: worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:22:18: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:18: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:18: EPOCH - 26 : training on 3420491 raw words (1974535 effective words) took 3.8s, 516170 effective words/s\n",
      "INFO - 00:22:19: EPOCH 27 - PROGRESS: at 22.56% examples, 426657 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:20: EPOCH 27 - PROGRESS: at 46.17% examples, 443750 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 00:22:21: EPOCH 27 - PROGRESS: at 69.22% examples, 444543 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:22: EPOCH 27 - PROGRESS: at 91.05% examples, 440075 words/s, in_qsize 13, out_qsize 1\n",
      "INFO - 00:22:23: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:23: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:23: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:23: EPOCH - 27 : training on 3420491 raw words (1974616 effective words) took 4.5s, 439371 effective words/s\n",
      "INFO - 00:22:24: EPOCH 28 - PROGRESS: at 19.36% examples, 373676 words/s, in_qsize 13, out_qsize 3\n",
      "INFO - 00:22:25: EPOCH 28 - PROGRESS: at 33.95% examples, 322841 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:26: EPOCH 28 - PROGRESS: at 49.93% examples, 320395 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:27: EPOCH 28 - PROGRESS: at 67.46% examples, 323167 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:28: EPOCH 28 - PROGRESS: at 84.59% examples, 325139 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:29: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:29: EPOCH - 28 : training on 3420491 raw words (1973414 effective words) took 6.0s, 330672 effective words/s\n",
      "INFO - 00:22:30: EPOCH 29 - PROGRESS: at 17.91% examples, 327112 words/s, in_qsize 14, out_qsize 2\n",
      "INFO - 00:22:31: EPOCH 29 - PROGRESS: at 35.41% examples, 336150 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:32: EPOCH 29 - PROGRESS: at 50.80% examples, 325805 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:33: EPOCH 29 - PROGRESS: at 69.23% examples, 334006 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 00:22:34: EPOCH 29 - PROGRESS: at 86.93% examples, 335297 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:35: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:35: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:35: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:35: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:35: EPOCH - 29 : training on 3420491 raw words (1974934 effective words) took 5.9s, 334818 effective words/s\n",
      "INFO - 00:22:36: EPOCH 30 - PROGRESS: at 14.69% examples, 280015 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 00:22:37: EPOCH 30 - PROGRESS: at 34.25% examples, 331125 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:38: EPOCH 30 - PROGRESS: at 51.37% examples, 333761 words/s, in_qsize 14, out_qsize 0\n",
      "INFO - 00:22:39: EPOCH 30 - PROGRESS: at 68.34% examples, 331023 words/s, in_qsize 12, out_qsize 1\n",
      "INFO - 00:22:40: EPOCH 30 - PROGRESS: at 89.27% examples, 344372 words/s, in_qsize 13, out_qsize 0\n",
      "INFO - 00:22:40: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:40: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:40: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:40: EPOCH - 30 : training on 3420491 raw words (1974758 effective words) took 5.5s, 356535 effective words/s\n",
      "INFO - 00:22:40: Word2Vec lifecycle event {'msg': 'training on 102614730 raw words (59231685 effective words) took 117.6s, 503548 effective words/s', 'datetime': '2021-05-09T00:22:40.663225', 'gensim': '4.0.1', 'python': '3.7.5 (default, Oct 25 2019, 10:52:18) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-19.6.0-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 1.96 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "#train word2vec model \n",
    "model.train(data['Documents'], total_examples=model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:21:22: Word2Vec lifecycle event {'fname_or_handle': 'model.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-04-29T22:21:22.924489', 'gensim': '4.0.1', 'python': '3.8.8 (default, Apr 13 2021, 19:58:26) \\n[GCC 7.3.0]', 'platform': 'Linux-4.15.0-142-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "INFO - 22:21:22: not storing attribute cum_table\n",
      "INFO - 22:21:22: saved model.bin\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save('model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction (word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base line number of features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(words, model, num_features):\n",
    "    \"\"\"\n",
    "    Average the word vectors for a set of words\n",
    "    \"\"\"\n",
    "    feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)  # words known to the model\n",
    "\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vec = np.add(feature_vec,model.wv[word])\n",
    "    \n",
    "    feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "def get_avg_feature_vecs(words, model, num_features):\n",
    "    \"\"\"\n",
    "    Calculate average feature vectors for all headlines \n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    feature_vecs = np.zeros((len(words),num_features), dtype='float32')  # pre-initialize (for speed)\n",
    "    \n",
    "    for word in words:\n",
    "        feature_vecs[counter] = make_feature_vec(word, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return feature_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = get_avg_feature_vecs(data['Documents'], model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove instances in test set that could not be represented as feature vectors\n",
    "nan_indices = list({x for x,y in np.argwhere(np.isnan(word2vec))})\n",
    "if len(nan_indices) > 0:\n",
    "    print('Removing {:d} instances from test set.'.format(len(nan_indices)))\n",
    "    word2vec = np.delete(word2vec, nan_indices, axis=0)\n",
    "    word2vec.drop(data.iloc[nan_indices, :].index, axis=0, inplace=True)\n",
    "    assert word2vec.shape[0] == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News Category</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Noun Phrases</th>\n",
       "      <th>Noun Count</th>\n",
       "      <th>Adjective Count</th>\n",
       "      <th>Verb Count</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.055361</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.489468</td>\n",
       "      <td>0.389286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621230</td>\n",
       "      <td>-0.032878</td>\n",
       "      <td>-0.113240</td>\n",
       "      <td>-0.350542</td>\n",
       "      <td>-0.084564</td>\n",
       "      <td>0.141340</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>-0.028677</td>\n",
       "      <td>-0.228371</td>\n",
       "      <td>-0.661437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.206475</td>\n",
       "      <td>-0.223033</td>\n",
       "      <td>0.390895</td>\n",
       "      <td>0.132415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237479</td>\n",
       "      <td>-0.250275</td>\n",
       "      <td>-0.061764</td>\n",
       "      <td>-0.402763</td>\n",
       "      <td>-0.023698</td>\n",
       "      <td>-0.627297</td>\n",
       "      <td>-0.115820</td>\n",
       "      <td>0.137561</td>\n",
       "      <td>-0.042825</td>\n",
       "      <td>-0.301519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.209188</td>\n",
       "      <td>-0.541559</td>\n",
       "      <td>0.265383</td>\n",
       "      <td>0.272109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819905</td>\n",
       "      <td>-0.628630</td>\n",
       "      <td>-0.246094</td>\n",
       "      <td>0.172992</td>\n",
       "      <td>-0.061221</td>\n",
       "      <td>0.641063</td>\n",
       "      <td>0.570838</td>\n",
       "      <td>0.560289</td>\n",
       "      <td>0.358528</td>\n",
       "      <td>-0.670001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.894695</td>\n",
       "      <td>-0.992983</td>\n",
       "      <td>-0.298582</td>\n",
       "      <td>-0.362631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380259</td>\n",
       "      <td>-0.767296</td>\n",
       "      <td>-0.975848</td>\n",
       "      <td>-0.347559</td>\n",
       "      <td>-0.095349</td>\n",
       "      <td>0.726570</td>\n",
       "      <td>0.460381</td>\n",
       "      <td>0.469100</td>\n",
       "      <td>0.352567</td>\n",
       "      <td>-0.934525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.044101</td>\n",
       "      <td>-0.751984</td>\n",
       "      <td>0.135745</td>\n",
       "      <td>0.037640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716525</td>\n",
       "      <td>-0.143298</td>\n",
       "      <td>-0.249741</td>\n",
       "      <td>-0.093775</td>\n",
       "      <td>0.275794</td>\n",
       "      <td>0.498189</td>\n",
       "      <td>0.350819</td>\n",
       "      <td>0.324995</td>\n",
       "      <td>0.294263</td>\n",
       "      <td>-0.212797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127595</th>\n",
       "      <td>world</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.022802</td>\n",
       "      <td>-0.905938</td>\n",
       "      <td>-0.137237</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>-0.463617</td>\n",
       "      <td>0.058749</td>\n",
       "      <td>-0.627807</td>\n",
       "      <td>0.232156</td>\n",
       "      <td>-0.321579</td>\n",
       "      <td>-0.591594</td>\n",
       "      <td>0.076990</td>\n",
       "      <td>-0.105051</td>\n",
       "      <td>0.569126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127596</th>\n",
       "      <td>sports</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.211614</td>\n",
       "      <td>-0.008620</td>\n",
       "      <td>-0.086450</td>\n",
       "      <td>0.280564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563488</td>\n",
       "      <td>-0.361268</td>\n",
       "      <td>-0.459734</td>\n",
       "      <td>-0.018276</td>\n",
       "      <td>0.077644</td>\n",
       "      <td>-0.300676</td>\n",
       "      <td>-0.209231</td>\n",
       "      <td>-0.541929</td>\n",
       "      <td>0.168749</td>\n",
       "      <td>-0.367598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127597</th>\n",
       "      <td>sports</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.097023</td>\n",
       "      <td>-0.319842</td>\n",
       "      <td>-0.016024</td>\n",
       "      <td>-0.086342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534790</td>\n",
       "      <td>-0.440539</td>\n",
       "      <td>-0.260372</td>\n",
       "      <td>-0.423392</td>\n",
       "      <td>0.239280</td>\n",
       "      <td>-0.125498</td>\n",
       "      <td>-0.429946</td>\n",
       "      <td>-0.387016</td>\n",
       "      <td>0.422862</td>\n",
       "      <td>-0.818029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127598</th>\n",
       "      <td>business</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.810561</td>\n",
       "      <td>-0.740219</td>\n",
       "      <td>-0.542993</td>\n",
       "      <td>0.131120</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410788</td>\n",
       "      <td>-0.506708</td>\n",
       "      <td>-0.501324</td>\n",
       "      <td>-0.352074</td>\n",
       "      <td>0.023445</td>\n",
       "      <td>-0.428003</td>\n",
       "      <td>0.191768</td>\n",
       "      <td>0.358949</td>\n",
       "      <td>0.569395</td>\n",
       "      <td>0.283652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127599</th>\n",
       "      <td>business</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.116780</td>\n",
       "      <td>0.809430</td>\n",
       "      <td>0.574082</td>\n",
       "      <td>0.618222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311761</td>\n",
       "      <td>-0.072696</td>\n",
       "      <td>-0.340002</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>-0.775197</td>\n",
       "      <td>-0.520676</td>\n",
       "      <td>-0.377293</td>\n",
       "      <td>0.628833</td>\n",
       "      <td>0.583953</td>\n",
       "      <td>-1.269253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127600 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       News Category  Word Count  Noun Phrases  Noun Count  Adjective Count  \\\n",
       "0           business          18             4          12                3   \n",
       "1           business          27             5          15                4   \n",
       "2           business          24             5          17                4   \n",
       "3           business          28             3          19                6   \n",
       "4           business          28             4          16                7   \n",
       "...              ...         ...           ...         ...              ...   \n",
       "127595         world          19             3           9                4   \n",
       "127596        sports          41             7          17                9   \n",
       "127597        sports          20             5           9                3   \n",
       "127598      business          21             4          10                4   \n",
       "127599      business          19             4           8                4   \n",
       "\n",
       "        Verb Count         0         1         2         3  ...        90  \\\n",
       "0                2  0.055361  0.005058  0.489468  0.389286  ...  0.621230   \n",
       "1                3  0.206475 -0.223033  0.390895  0.132415  ...  0.237479   \n",
       "2                2  0.209188 -0.541559  0.265383  0.272109  ...  0.819905   \n",
       "3                3 -0.894695 -0.992983 -0.298582 -0.362631  ...  0.380259   \n",
       "4                3  0.044101 -0.751984  0.135745  0.037640  ...  0.716525   \n",
       "...            ...       ...       ...       ...       ...  ...       ...   \n",
       "127595           5  0.022802 -0.905938 -0.137237  0.068300  ... -0.012326   \n",
       "127596          10 -0.211614 -0.008620 -0.086450  0.280564  ...  0.563488   \n",
       "127597           3  0.097023 -0.319842 -0.016024 -0.086342  ...  0.534790   \n",
       "127598           4 -0.810561 -0.740219 -0.542993  0.131120  ... -0.410788   \n",
       "127599           4 -0.116780  0.809430  0.574082  0.618222  ...  0.311761   \n",
       "\n",
       "              91        92        93        94        95        96        97  \\\n",
       "0      -0.032878 -0.113240 -0.350542 -0.084564  0.141340  0.004108 -0.028677   \n",
       "1      -0.250275 -0.061764 -0.402763 -0.023698 -0.627297 -0.115820  0.137561   \n",
       "2      -0.628630 -0.246094  0.172992 -0.061221  0.641063  0.570838  0.560289   \n",
       "3      -0.767296 -0.975848 -0.347559 -0.095349  0.726570  0.460381  0.469100   \n",
       "4      -0.143298 -0.249741 -0.093775  0.275794  0.498189  0.350819  0.324995   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "127595 -0.463617  0.058749 -0.627807  0.232156 -0.321579 -0.591594  0.076990   \n",
       "127596 -0.361268 -0.459734 -0.018276  0.077644 -0.300676 -0.209231 -0.541929   \n",
       "127597 -0.440539 -0.260372 -0.423392  0.239280 -0.125498 -0.429946 -0.387016   \n",
       "127598 -0.506708 -0.501324 -0.352074  0.023445 -0.428003  0.191768  0.358949   \n",
       "127599 -0.072696 -0.340002  0.011501 -0.775197 -0.520676 -0.377293  0.628833   \n",
       "\n",
       "              98        99  \n",
       "0      -0.228371 -0.661437  \n",
       "1      -0.042825 -0.301519  \n",
       "2       0.358528 -0.670001  \n",
       "3       0.352567 -0.934525  \n",
       "4       0.294263 -0.212797  \n",
       "...          ...       ...  \n",
       "127595 -0.105051  0.569126  \n",
       "127596  0.168749 -0.367598  \n",
       "127597  0.422862 -0.818029  \n",
       "127598  0.569395  0.283652  \n",
       "127599  0.583953 -1.269253  \n",
       "\n",
       "[127600 rows x 106 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v = pd.DataFrame(word2vec)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "w2v.reset_index(drop=True, inplace=True)\n",
    "#df = pd.concat([df1, df2], axis=1)\n",
    "w2v = pd.concat([data[['News Category','Word Count','Noun Phrases','Noun Count',\n",
    "                                         'Adjective Count','Verb Count']],w2v],axis=1)\n",
    "\n",
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X dataframe \n",
    "X = w2v.drop(['News Category'],axis=1) \n",
    "# y series\n",
    "y = w2v['News Category']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifications Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a Logistic Regression model to labeled training data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4b1f97971910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlr_tt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "print(\"Fitting a Logistic Regression model to labeled training data...\")\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "logit.fit(X_train,y_train)pre\n",
    "\n",
    "lr_tt = round((time() - start_time) / 60, 2)\n",
    "\n",
    "print('Time to train Logistic Regression Model: {} mins'.format(lr_tt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='newton-cg')\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "lr_acc = []\n",
    "\n",
    "for train_index, vaild_index in skf.split(X_train,y_train):\n",
    "    x_t, x_v = X_train.iloc[train_index], X_train.iloc[vaild_index]\n",
    "    y_t, y_v = y_train.iloc[train_index], y_train.iloc[vaild_index]\n",
    "    lr.fit(x_t, y_t)\n",
    "    lr_acc.append(lr.score(x_v, y_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8866435288849082, 0.8955441110613525, 0.8924652933273622, 0.8947044334975369, 0.8905620241827138]\n"
     ]
    }
   ],
   "source": [
    "print(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8919838781907747\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(lr_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_test = y_test.to_numpy()\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "lr_acc = accuracy_score(y_test,y_pred)\n",
    "lr_recall = recall_score(y_test,y_pred,average='macro')\n",
    "lr_precision = precision_score(y_test,y_pred,average='macro')\n",
    "lr_f1 = f1_score(y_test,y_pred,average='macro')\n",
    "\n",
    "y_pred_roc = OneHotEncoder().fit_transform(y_pred.reshape(-1, 1)).toarray()\n",
    "y_test_roc = OneHotEncoder().fit_transform(y_test.reshape(-1, 1)).toarray()\n",
    "lr_roc = roc_auc_score(y_test_roc,y_pred_roc,multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.8925548589341693 0.8926048131834262 0.8924548445701799 0.8924284148593548 0.9283909985869295\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression: \",lr_acc,lr_recall,lr_precision,lr_f1,lr_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pkl_Filename = \"Pickle_RL_Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(lr, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AG_News_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
